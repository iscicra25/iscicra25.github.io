---
title: "Overview"
---
Consider an aerial vehicle moving through a disaster scenario, mapping the environment and looking for survivors. In such safety-critical and challenging scenarios, it is difficult to know robot dynamics and environment state with certainty. Similar situations arise as the robots, like elderly-care robots, or robots waiting tables, move out of labs and structured industrial environments. 

The requirement of safety-critical control has been recognized by Robotics and control theory researchers for decades. To list a few of the approaches for Safe or Robust control include: Model Predictive Control, Reference governor, Reachability, Contraction Theory, Control Barrier Functions. 

The progress in machine learning algorithms has made it possible to learn unknown dynamics in the control loop. This direction has produced promising results in the area of model-free and model-based reinforcement learning, inverse reinforcement learning. These learning directions although empirically impressive do not provide guarantees for safety.

This workshop seeks to bring the experts from two communities--learning and safe-control--together and highlight the recent works at the intersection of machine learning and guaranteed safe control. The workshop features talks from communities in machine learning and control systems with an emphasis on robotic applications, for the sake of promoting interdisciplinary research from different perspectives. We invite submissions from a broad range of topics that investigate the format safety of robots while dealing with uncertainties introduced when the uncertain robot-dynamics are being learned or the environment state is being estimated. We provide a non-exhaustive list of topics that might be of interest to the community:

Control-theoretic techniques for safe task execution
Control Barrier Function
Reachability Analysis
Model Predictive Control
Reference Governor Control
Contraction Theory


Machine learning techniques (with or without control-theoretic guarantees) for safe task execution
Dynamics model learning or system identification
Learning for collision avoidance
Mapping dynamic environments

ML techniques with control-theoretic guarantees
Gaussian process dynamics models for safe control
Neural networks/SVM for environment models used for safe control
Safe Reinforcement Learning

