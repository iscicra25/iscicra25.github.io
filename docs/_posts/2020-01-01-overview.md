---
title: "Overview"
---

## Important Details

* **Workshop date and time**: May 19th or 23rd, 2025 in Georgia, Atlanta, USA at ICRAâ€™25.
* **Registration link**: 
* **Submission deadline**: 
* **Submission link**: 
* **Paper format**: [IEEE RAS format](http://ras.papercept.net/conferences/support/support.php)
* **Recommended length**: 2-4 pages
* **Review process**: single-blind
* **Notification of acceptance**: 

 Robot and automation systems are deployed in increasingly complex environments and expected to carry out increasingly sophisticated tasks. This places stringent expectations on the perception, planning, and control autonomy stack to enforce operational constraints and provide safety guarantees. While there are well-established techniques with theoretical foundations for enabling safe control synthesis, including model predictive control, reachability analysis, and control barrier functions, these methods commonly rely on clean, explicit, mathematical definitions of safety constraints with known system and environment models. Many current applications bring in perception uncertainty or semantic concepts in the task specifications, making the concept of safety much more nuanced. Contrary to the assumptions of current methods, the safety requirements may be specified in an implicit, abstract, or incomplete way.

This workshop aims to investigate the concept and formulation of such ``intangible'' safety constraints. Such constraints may not be specified as mathematical expressions but described in natural language semantic concepts, described by sensor data anomalies, or inferred from demonstrations and prior experience. Largely unexplored are the techniques for identification of safety constraints from demonstration or for propagation of uncertainty in the constraints. Different interesting facets include, but are not limited to, inverse identification of safety constraints from demonstration, compatibility of learned constraints and control design methodology, interaction with humans or vision-language models for safety information, uncertainty quantification (methods such as Bayesian neural networks, conformal prediction, distributionally robust optimization) in the specification of safety and the design of safe planning and control algorithms. The workshop will invite experts in the field to discuss the formulation, optimization, and guarantees with intangible safety constraints.
