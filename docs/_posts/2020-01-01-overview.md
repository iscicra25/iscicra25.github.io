---
title: "Overview"
---
Guaranteeing safety and stability of task execution is a key requirement for effective deployment of autonomous robots. Extensive research in control theory and robotics has enabled effective techniques with strong theoretical guarantees based on model predictive control, reference governor design, Hamilton-Jacobi reachability, control Lyapunov and barrier functions, and contraction theory. Existing techniques, however, predominantly assume that prior knowledge about the task safety constraints and robot motion dynamics is available. As autonomous robots transition from labs and industrial environments to unstructured and dynamically changing real-world environments, these assumptions are impossible to satisfy. An unmanned aerial vehicle aiding in disaster response has to operate in an unpredictable environment, subject to extreme disturbances. A walking robot providing last-mile delivery has to traverse changing terrains and negotiate with pedestrian and vehicle traffic. Even a household cleaning robot has to manipulate objects safely in cluttered rooms and in close proximity to humans.

The progress in machine learning algorithms has made it possible to learn unknown dynamics in the control loop. This direction has produced promising results in the area of dynamics learning, learning for collision avoidance and mapping dynamic environments using techniques like model-free and model-based deep reinforcement learning, inverse reinforcement learning etc. These learning algorithms although empirically impressive do not provide guarantees for safety.

This workshop seeks to bring the experts from two communities-- safe-control and learning--together and highlight the recent works at the intersection of the two fields. The workshop will feature talks from the two communities with an emphasis on robotic applications, aiming to promote interdisciplinary research from different perspectives. We invite submissions from a broad range of topics that investigate the format safety of robots while dealing with uncertainties introduced when the uncertain robot-dynamics are being learned or the environment state is being estimated. We provide a non-exhaustive list of topics that might be of interest to the target audience for this workshop:

1. Control-theoretic techniques for safe task execution
   1. Control Barrier Function
   2. Reachability Analysis
   3. Model Predictive Control
   4. Reference Governor Control
   5. Contraction Theory
2. Machine learning techniques (with or without control-theoretic guarantees) for safe task execution
   1. Dynamics model learning or system identification
   2. Learning for collision avoidance
   3. Mapping dynamic environments
3. ML techniques with control-theoretic guarantees
   1. Gaussian process dynamics models for safe control
   2. Neural networks/SVM for environment models used for safe control
   3. Safe Reinforcement Learning

