---
title: "Overview"
---

## Important Details

* **Workshop date and time**: May 13th or 17th, 2024 in Yokohama, Japan at ICRAâ€™24.
* **Registration link**: 
* **Submission deadline**: 
* **Submission link**: 
* **Paper format**: [IEEE RAS format](http://ras.papercept.net/conferences/support/support.php)
* **Recommended length**: 2-4 pages
* **Review process**: single-blind
* **Notification of acceptance**: 

Guaranteeing safety is crucial for the effective deployment of robots, in general autonomous systems. For realizing the fully reliable system, all the components in perception, navigation, and control must incorporate safety considerations. Control theory research has established techniques with theoretical safety and stability guarantees based on model predictive control, reference governor design, Hamilton-Jacobi reachability, control Lyapunov and barrier functions, and contraction theory. Similarly, formal methods techniques based on SMT solvers and hybrid system verification have been used to guarantee safety in systems. Many existing techniques, however, predominantly assume that the robot motion dynamics and safety constraints are precisely known in advance. This assumption cannot be satisfied in the unstructured and dynamic real-world conditions. For example, an aerial vehicle aiding in disaster response must operate in an unpredictable environment subject to extreme disturbances. Similarly, a walking robot providing last-mile delivery has to traverse changing terrain while negotiating pedestrian traffic.

Recent progress in machine learning allows learning robot dynamics and environment models from sensory data. For example, Gaussian Process regression and Koopman operator theory have shown promise in learning dynamics models. Similarly, deep neural network models have enabled impressive results in 3D reconstruction from visual data. Despite their empirical success, these works usually do not provide theoretical guarantees for safety and stability. Recent works in Bayesian deep learning have allowed us to associate uncertainty with the learned predictions, making it possible to use safe control approaches in machine learning enabled systems. However, the trustworthiness of uncertainty estimates of Bayesian deep learning models still remains an open problem.

This workshop will bring together experts from multiple communities -- robotics, control theory, computer vision, and machine learning -- to address challenges in safe and stable robot control with learned motion and environment models.
