---
title: "Call for Papers"
---
We invite submissions from a broad range of topics that investigate the formal safety of robots when dealing with uncertainty introduced when the robot dynamics models are learned or the environment state is estimated. We provide a non-exhaustive list of topics that might be of interest to the target audience for this workshop:

  1. Control-theoretic techniques for safe task execution, including control barrier functions, reachability analysis, model predictive control, reference governor control, contraction theory.
  2. Machine learning techniques for safe task execution, including model-based reinforcement learning, robot dynamics model learning and system identification, learning 3-D environment shape and dynamics.

Priority will be given to papers that bridge the gap between the two areas to provide safety and stability guarantees for systems with learned motion and environment dynamics. The review committee will judge the contributions based on the following questions:

  1. What is the approach for *estimating* robot dynamics or environment models?
  2. How are the estimation errors *quantified and used* in verifying safety or stability?
  3. What is the key *contribution* of this approach?
  4. What is a key research problem that the community should address in *future work* and whose resolution will significantly impact your work?

#### Spotlight Video
Accepted papers will be required to submit a spotlight video that provides a demo of the proposed approach and answers the four key questions related to our workshop. In the demo part of the video, the authors are encouraged to demonstrate the operation of their system (either real or simulated) in a safety critical scenario. The spotlight videos will be presented during the time allocated for the poster session. 
